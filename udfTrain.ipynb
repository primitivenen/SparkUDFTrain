{"cells":[{"cell_type":"markdown","source":["# Embarrassingly Parallel Model Training on Spark — Pandas UDF"],"metadata":{}},{"cell_type":"code","source":["# Make Temporary Directory\ndbutils.fs.mkdirs(\"dbfs:/FileStore/temporary\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: True</div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Import required packages\nimport joblib # To Pickel Trained model file \nimport numpy as np # To create random data\nimport pandas as pd # To operate on data in Python Process\nfrom sklearn.linear_model import LinearRegression # To train Linear Regression models\n\nfrom pyspark.sql.functions import pandas_udf, PandasUDFType # Pandas UDF functions to call Python processes from spark\nfrom pyspark.sql.types import DoubleType, StringType, ArrayType # Data types to capture reurn at Spark End"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Create Random linear dataset for training\ndf1 = pd.DataFrame({'x': np.random.normal(size=100)})\ndf1['y'] = df1['x']*2.5 + np.random.normal(scale=0.5, size=100) # DF1 is dummy Linear data Y = 2.5*x + random noise of 100 datapoints\ndf1['name'] = 'df1'\ndf1.to_csv('df1.csv') # Save the dataframe as .csv"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["%sh\n# Zip the CSV file\ngzip -f \"df1.csv\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Move the zipped dataset to dbfs:/FileStore/temporary\ndbutils.fs.mv(\"file:/databricks/driver/df1.csv.gz\", \"dbfs:/FileStore/temporary/df1.csv.gz\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: True</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Create Random linear dataset for training\ndf2 = pd.DataFrame({'x': np.random.normal(size=100)})\ndf2['y'] = df2['x']*3.0 + np.random.normal(scale=0.3, size=100) # DF2 is dummy Linear data Y = 3.0*x + random noise of 100 datapoints\ndf2['name'] = 'df2'\ndf2.to_csv('df2.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["%sh\n# Zip the CSV file\ngzip -f \"df2.csv\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Move the zipped dataset to dbfs:/FileStore/temporary\ndbutils.fs.mv(\"file:/databricks/driver/df2.csv.gz\", \"dbfs:/FileStore/temporary/df2.csv.gz\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: True</div>"]}}],"execution_count":9},{"cell_type":"code","source":["%fs ls dbfs:/FileStore/temporary"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/temporary/df1.csv.gz</td><td>df1.csv.gz</td><td>2272</td></tr><tr><td>dbfs:/FileStore/temporary/df2.csv.gz</td><td>df2.csv.gz</td><td>2264</td></tr></tbody></table></div>"]}}],"execution_count":10},{"cell_type":"code","source":["# Create spark data-frame from .csv.gz files\nsparkDF = (spark.read\n            .option(\"header\", \"true\")\n            .option(\"delimiter\", \",\")\n            .option(\"inferSchema\", \"true\") \n            .csv('dbfs:/FileStore/temporary/df*.csv.gz'))\n\nsparkDF.rdd.getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: 2</div>"]}}],"execution_count":11},{"cell_type":"code","source":["# Check the schema for the spark dataframe\nsparkDF.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- _c0: integer (nullable = true)\n-- x: double (nullable = true)\n-- y: double (nullable = true)\n-- name: string (nullable = true)\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# Pandas UDF to Train the models\n@pandas_udf(returnType=DoubleType())\ndef train_lm_pandas_udf(*cols):\n    df = pd.concat(cols, axis=1) # Create pandas dataframe using input Spark DataFrame columns\n    df.columns = ['x', 'y', 'name']\n    modelUDF = LinearRegression() # Scikit-Learn Linear Regression \n    modelUDF.fit(pd.DataFrame(df['x']),df['y']) # Fit Scikit-Learn Linear Regression Model\n    sig = df.loc[0,'name'] # Unique Identiter for model files, obtained from one of the columns in dataset\n    joblib.dump(modelUDF, 'new_modelUDF{signature}.joblib'.format(signature=sig)) # Pickel Thetrained model file\n    return pd.Series(modelUDF.predict(pd.DataFrame(df['x']))) # Returns Predicted values on training data"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["# Create sparkDF2 to kick off training\ncolumn_names = ['x', 'y', 'name']\nsparkDF2 = sparkDF.select(train_lm_pandas_udf(*column_names).alias(\"TrainPrediction\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["# Initiate Parallel training jobs\nsparkDF2.rdd.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: 200</div>"]}}],"execution_count":15},{"cell_type":"code","source":["%fs ls file:/databricks/driver"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>file:/databricks/driver/conf/</td><td>conf/</td><td>4096</td></tr><tr><td>file:/databricks/driver/new_modelUDFdf2.joblib</td><td>new_modelUDFdf2.joblib</td><td>574</td></tr><tr><td>file:/databricks/driver/derby.log</td><td>derby.log</td><td>726</td></tr><tr><td>file:/databricks/driver/new_modelUDFdf1.joblib</td><td>new_modelUDFdf1.joblib</td><td>574</td></tr><tr><td>file:/databricks/driver/logs/</td><td>logs/</td><td>4096</td></tr><tr><td>file:/databricks/driver/ganglia/</td><td>ganglia/</td><td>4096</td></tr><tr><td>file:/databricks/driver/eventlogs/</td><td>eventlogs/</td><td>4096</td></tr></tbody></table></div>"]}}],"execution_count":16},{"cell_type":"code","source":["# Load trained models to varify \nmodeldf1 = joblib.load('new_modelUDFdf1.joblib')\nmodeldf2 = joblib.load('new_modelUDFdf2.joblib')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["modeldf1.coef_"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[20]: array([2.53213828])</div>"]}}],"execution_count":18},{"cell_type":"code","source":["modeldf2.coef_"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[21]: array([3.04369797])</div>"]}}],"execution_count":19},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":20}],"metadata":{"name":"udfTrain","notebookId":4386531222885202},"nbformat":4,"nbformat_minor":0}
